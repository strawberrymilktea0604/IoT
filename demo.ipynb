{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c8df8e-75e4-4aa1-9a57-9fce262b1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d1d0e4d-be43-4828-82ed-f9ffa4704d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tìm thấy 45 file JSON annotation\n",
      "Đang xây dựng class mapping từ annotation...\n",
      "Đã lưu 2 lớp vào classes.txt\n",
      "Đã xử lý 45/45 file annotation\n",
      "Dữ liệu đã được chuyển đổi và lưu vào C:/Users/minhk/Downloads/IoT/model/dataset\n",
      "Đã tạo file cấu hình YAML: C:/Users/minhk/Downloads/IoT/model/dataset\\data.yaml\n"
     ]
    }
   ],
   "source": [
    "def convert_multiple_json_to_yolo(annotations_dir, images_dir, output_dir, class_mapping=None):\n",
    "    \"\"\"\n",
    "    Chuyển đổi nhiều file JSON annotation thành định dạng YOLO, hỗ trợ kiểu Supervisely (objects/classTitle/points.exterior).\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels'), exist_ok=True)\n",
    "    \n",
    "    json_files = glob.glob(os.path.join(annotations_dir, '*.json'))\n",
    "    if len(json_files) == 0:\n",
    "        print(f\"Không tìm thấy file JSON nào trong {annotations_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Tìm thấy {len(json_files)} file JSON annotation\")\n",
    "    \n",
    "    # Build class_mapping nếu chưa có\n",
    "    if class_mapping is None:\n",
    "        print(\"Đang xây dựng class mapping từ annotation...\")\n",
    "        class_names = set()\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                # Supervisely format\n",
    "                if 'objects' in data:\n",
    "                    for obj in data['objects']:\n",
    "                        if 'classTitle' in obj:\n",
    "                            class_names.add(obj['classTitle'])\n",
    "                # Các format khác nếu cần\n",
    "                elif 'shapes' in data:\n",
    "                    for shape in data['shapes']:\n",
    "                        class_names.add(shape['label'])\n",
    "                elif 'annotations' in data:\n",
    "                    for ann in data['annotations']:\n",
    "                        if 'category_name' in ann:\n",
    "                            class_names.add(ann['category_name'])\n",
    "                        elif 'category_id' in ann and 'categories' in data:\n",
    "                            for cat in data['categories']:\n",
    "                                if cat['id'] == ann['category_id']:\n",
    "                                    class_names.add(cat['name'])\n",
    "                                    break\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi khi đọc file {json_file}: {e}\")\n",
    "        class_mapping = {name: idx for idx, name in enumerate(sorted(class_names))}\n",
    "        if len(class_mapping) == 0:\n",
    "            print(\"Không thể tạo class mapping từ annotation. Vui lòng cung cấp class_mapping.\")\n",
    "            return\n",
    "    \n",
    "    # Lưu class_mapping ra file\n",
    "    with open(os.path.join(output_dir, 'classes.txt'), 'w', encoding='utf-8') as f:\n",
    "        for class_name, class_id in sorted(class_mapping.items(), key=lambda x: x[1]):\n",
    "            f.write(f\"{class_name}\\n\")\n",
    "    print(f\"Đã lưu {len(class_mapping)} lớp vào classes.txt\")\n",
    "    \n",
    "    processed_files = 0\n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            base_name = os.path.basename(json_file)\n",
    "            if '.jpg.json' in base_name:\n",
    "                img_name = base_name.replace('.json', '')\n",
    "            elif '.png.json' in base_name:\n",
    "                img_name = base_name.replace('.json', '')\n",
    "            else:\n",
    "                img_name = os.path.splitext(base_name)[0] + '.jpg'\n",
    "            src_img_path = os.path.join(images_dir, img_name)\n",
    "            dst_img_path = os.path.join(output_dir, 'images', img_name)\n",
    "            img_base_name = os.path.splitext(img_name)[0]\n",
    "            label_file = os.path.join(output_dir, 'labels', img_base_name + '.txt')\n",
    "            with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            if os.path.exists(src_img_path):\n",
    "                shutil.copy(src_img_path, dst_img_path)\n",
    "            else:\n",
    "                print(f\"Không tìm thấy hình ảnh {src_img_path}\")\n",
    "                continue\n",
    "            # Lấy kích thước ảnh\n",
    "            if 'imageWidth' in data and 'imageHeight' in data:\n",
    "                img_width = data['imageWidth']\n",
    "                img_height = data['imageHeight']\n",
    "            elif 'width' in data and 'height' in data:\n",
    "                img_width = data['width']\n",
    "                img_height = data['height']\n",
    "            elif 'size' in data and 'width' in data['size'] and 'height' in data['size']:\n",
    "                img_width = data['size']['width']\n",
    "                img_height = data['size']['height']\n",
    "            else:\n",
    "                from PIL import Image\n",
    "                try:\n",
    "                    with Image.open(src_img_path) as img:\n",
    "                        img_width, img_height = img.size\n",
    "                except:\n",
    "                    print(f\"Không thể đọc kích thước hình ảnh {src_img_path}\")\n",
    "                    continue\n",
    "            # Tạo file label YOLO\n",
    "            with open(label_file, 'w') as f:\n",
    "                # Supervisely format\n",
    "                if 'objects' in data:\n",
    "                    for obj in data['objects']:\n",
    "                        label = obj['classTitle']\n",
    "                        points = obj['points']['exterior']\n",
    "                        if len(points) != 2:\n",
    "                            continue\n",
    "                        x1, y1 = points[0]\n",
    "                        x2, y2 = points[1]\n",
    "                        x_min = min(x1, x2)\n",
    "                        y_min = min(y1, y2)\n",
    "                        x_max = max(x1, x2)\n",
    "                        y_max = max(y1, y2)\n",
    "                        width = x_max - x_min\n",
    "                        height = y_max - y_min\n",
    "                        x_center = x_min + width / 2\n",
    "                        y_center = y_min + height / 2\n",
    "                        x_center /= img_width\n",
    "                        y_center /= img_height\n",
    "                        width /= img_width\n",
    "                        height /= img_height\n",
    "                        class_id = class_mapping.get(label, 0)\n",
    "                        f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "                # Các format khác (labelme, coco) nếu cần\n",
    "                elif 'shapes' in data:\n",
    "                    for shape in data['shapes']:\n",
    "                        if shape['shape_type'] == 'rectangle':\n",
    "                            label = shape['label']\n",
    "                            points = shape['points']\n",
    "                            x1, y1 = points[0]\n",
    "                            x2, y2 = points[1]\n",
    "                            x_min = min(x1, x2)\n",
    "                            y_min = min(y1, y2)\n",
    "                            x_max = max(x1, x2)\n",
    "                            y_max = max(y1, y2)\n",
    "                            width = x_max - x_min\n",
    "                            height = y_max - y_min\n",
    "                            x_center = x_min + width / 2\n",
    "                            y_center = y_min + height / 2\n",
    "                            x_center /= img_width\n",
    "                            y_center /= img_height\n",
    "                            width /= img_width\n",
    "                            height /= img_height\n",
    "                            class_id = class_mapping.get(label, 0)\n",
    "                            f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "                elif 'annotations' in data:\n",
    "                    for ann in data['annotations']:\n",
    "                        if 'bbox' in ann:\n",
    "                            if 'category_id' in ann:\n",
    "                                class_id = ann['category_id']\n",
    "                            elif 'category_name' in ann:\n",
    "                                class_id = class_mapping.get(ann['category_name'], 0)\n",
    "                            else:\n",
    "                                continue\n",
    "                            bbox = ann['bbox']  # [x, y, width, height]\n",
    "                            x_center = (bbox[0] + bbox[2]/2) / img_width\n",
    "                            y_center = (bbox[1] + bbox[3]/2) / img_height\n",
    "                            width = bbox[2] / img_width\n",
    "                            height = bbox[3] / img_height\n",
    "                            f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "            processed_files += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi xử lý file {json_file}: {e}\")\n",
    "    print(f\"Đã xử lý {processed_files}/{len(json_files)} file annotation\")\n",
    "    print(f\"Dữ liệu đã được chuyển đổi và lưu vào {output_dir}\")\n",
    "    create_data_yaml(output_dir, class_mapping)\n",
    "\n",
    "def create_data_yaml(output_dir, class_mapping):\n",
    "    \"\"\"Tạo file data.yaml cho YOLOv8\"\"\"\n",
    "    class_names = [name for name, _ in sorted(class_mapping.items(), key=lambda x: x[1])]\n",
    "    yaml_content = {\n",
    "        'path': os.path.abspath(output_dir),\n",
    "        'train': './images',\n",
    "        'val': './images',\n",
    "        'nc': len(class_names),\n",
    "        'names': class_names\n",
    "    }\n",
    "    yaml_file = os.path.join(output_dir, 'data.yaml')\n",
    "    import yaml\n",
    "    with open(yaml_file, 'w') as f:\n",
    "        yaml.dump(yaml_content, f, default_flow_style=False)\n",
    "    print(f\"Đã tạo file cấu hình YAML: {yaml_file}\")\n",
    "\n",
    "# Các đường dẫn\n",
    "annotations_dir = 'C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/annotations'\n",
    "images_dir = 'C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images'\n",
    "output_dir = 'C:/Users/minhk/Downloads/IoT/model/dataset'\n",
    "\n",
    "# Chạy hàm chuyển đổi\n",
    "convert_multiple_json_to_yolo(annotations_dir, images_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3112dd08-e4f8-444a-8251-eedceb921ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.126  Python-3.9.18 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/minhk/Downloads/IoT/model/dataset/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 259.066.9 MB/s, size: 2463.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\labels.cache... 45 images, 0 backgrounds, 1 corrupt: 100%|██\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\005.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\009.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.3022      1.3223      1.0841      1.0744      1.0623      1.0945      1.0893      1.1579      1.0835      1.2695      1.3175       1.113      1.3259       1.207       1.029      1.0884      1.3348      1.0344      1.3302      1.3182      1.3013        1.33      1.3374      1.0893      1.0893      1.0747\n",
      "      1.0867      1.2417      1.0791      1.3228      1.0311      1.3339      1.3348      1.1824      1.3214      1.3235      1.2944       1.205      1.1221      1.2463      1.1656      1.0813      1.3266      1.3296      1.0859        1.33      1.0919      1.1205      1.0911      1.0887      1.0792      1.3214\n",
      "      1.3395]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\018.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\022.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\031.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\041.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 188.269.6 MB/s, size: 3609.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\labels.cache... 45 images, 0 backgrounds, 1 corrupt: 100%|████\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\005.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\009.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.3022      1.3223      1.0841      1.0744      1.0623      1.0945      1.0893      1.1579      1.0835      1.2695      1.3175       1.113      1.3259       1.207       1.029      1.0884      1.3348      1.0344      1.3302      1.3182      1.3013        1.33      1.3374      1.0893      1.0893      1.0747\n",
      "      1.0867      1.2417      1.0791      1.3228      1.0311      1.3339      1.3348      1.1824      1.3214      1.3235      1.2944       1.205      1.1221      1.2463      1.1656      1.0813      1.3266      1.3296      1.0859        1.33      1.0919      1.1205      1.0911      1.0887      1.0792      1.3214\n",
      "      1.3395]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\018.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\022.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\031.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\041.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      8.67G      2.454      3.897      1.629       3106        640: 100%|██████████| 3/3 [01:04<00:00, 21.51\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [01:04<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447     0.0394     0.0292     0.0213      0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      8.72G      2.635      3.893      1.682       4649        640: 100%|██████████| 3/3 [00:51<00:00, 17.28\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:22<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.052     0.0385     0.0281     0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      8.91G      2.304       3.74      1.527       6294        640: 100%|██████████| 3/3 [00:42<00:00, 14.09\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:22<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447     0.0852     0.0683     0.0487     0.0297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      8.48G      2.193      3.533      1.395       5654        640: 100%|██████████| 3/3 [00:55<00:00, 18.46\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:27<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447     0.0961     0.0781      0.056     0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50       6.7G       2.06      3.234      1.338       4041        640: 100%|██████████| 3/3 [00:40<00:00, 13.44\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447     0.0961     0.0744     0.0719     0.0422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      6.91G      2.002      2.917      1.277       3881        640: 100%|██████████| 3/3 [00:23<00:00,  7.93\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.137       0.11      0.131     0.0758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      8.81G      2.019      2.659      1.226       6567        640: 100%|██████████| 3/3 [00:58<00:00, 19.58\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447       0.17      0.147      0.165       0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      7.12G      2.016      2.593      1.224       6776        640: 100%|██████████| 3/3 [00:38<00:00, 12.89\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:28<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.194      0.178      0.191      0.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      5.67G      1.951      2.299      1.175       4341        640: 100%|██████████| 3/3 [00:38<00:00, 13.00\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:19<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.212      0.237      0.238      0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      7.03G      1.911      2.199      1.171       4824        640: 100%|██████████| 3/3 [00:30<00:00, 10.02\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:32<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.216      0.244      0.252      0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      5.63G      2.018      2.189      1.165       7501        640: 100%|██████████| 3/3 [00:53<00:00, 17.75\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:19<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.844      0.224      0.269      0.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      5.24G       2.02      2.074      1.149       5851        640: 100%|██████████| 3/3 [00:34<00:00, 11.44\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:20<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.848      0.231      0.275      0.146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      6.09G      1.944      1.973      1.113       5587        640: 100%|██████████| 3/3 [00:50<00:00, 16.75\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.826      0.243      0.274      0.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      6.54G      2.049      1.935      1.161       2848        640: 100%|██████████| 3/3 [00:47<00:00, 15.92\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.845      0.251      0.285      0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      7.63G      1.801      1.774      1.111       2877        640: 100%|██████████| 3/3 [00:29<00:00,  9.85\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.838      0.231      0.265       0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      7.13G      1.895      1.775      1.118       3754        640: 100%|██████████| 3/3 [00:42<00:00, 14.14\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.838      0.224      0.259      0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      8.16G      1.897      1.772      1.117       4696        640: 100%|██████████| 3/3 [00:44<00:00, 14.82\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.843      0.236      0.274      0.146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      6.86G      2.055      1.881      1.132       7244        640:  33%|███▎      | 1/3 [00:25<00:50, 25.09"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      6.89G      1.917      1.768      1.096       4859        640: 100%|██████████| 3/3 [01:13<00:00, 24.47\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:24<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.837      0.249      0.282      0.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      7.59G      1.943      1.748      1.101       4367        640: 100%|██████████| 3/3 [00:46<00:00, 15.64\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.841      0.258      0.295      0.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      5.72G      1.949      1.705      1.107       4810        640: 100%|██████████| 3/3 [00:42<00:00, 14.29\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.847      0.257      0.301      0.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      6.58G      1.827      1.654      1.069       4501        640: 100%|██████████| 3/3 [00:54<00:00, 18.15\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.856      0.258      0.303      0.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      6.06G      1.866       1.58      1.083       4566        640: 100%|██████████| 3/3 [00:47<00:00, 15.92\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.865      0.261      0.308      0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      7.89G      1.895      1.617      1.072       6724        640: 100%|██████████| 3/3 [00:45<00:00, 15.17\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:25<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.867      0.267      0.312      0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      6.71G      1.817      1.634      1.091       4264        640: 100%|██████████| 3/3 [00:43<00:00, 14.42\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.869      0.269      0.318       0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      7.58G      1.797      1.522      1.073       4479        640: 100%|██████████| 3/3 [00:46<00:00, 15.47\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [01:12<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447       0.87      0.268       0.32       0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      6.87G      1.806      1.519      1.073       6034        640: 100%|██████████| 3/3 [00:57<00:00, 19.01\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:27<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.863      0.265      0.317      0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      9.29G      1.806      1.493      1.078       6200        640: 100%|██████████| 3/3 [00:46<00:00, 15.45\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:27<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447       0.84      0.265      0.315      0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      7.76G      1.751      1.472      1.065       5708        640: 100%|██████████| 3/3 [00:42<00:00, 14.00\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:25<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447       0.29      0.333      0.341      0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50       7.9G      1.688      1.421      1.043       5930        640: 100%|██████████| 3/3 [00:44<00:00, 14.82\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:25<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447       0.29      0.333      0.341      0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      9.26G      1.754      1.424      1.056       4476        640: 100%|██████████| 3/3 [00:49<00:00, 16.65\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.307      0.353      0.368      0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      6.07G      1.706      1.393      1.049       4697        640: 100%|██████████| 3/3 [00:51<00:00, 17.22\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.326      0.377      0.395      0.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      7.41G      1.634      1.357      1.052       3743        640: 100%|██████████| 3/3 [00:40<00:00, 13.53\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.344        0.4      0.421       0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      8.18G      1.788      1.391      1.047       5759        640: 100%|██████████| 3/3 [00:48<00:00, 16.05\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:29<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.344        0.4      0.421       0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50       7.9G      1.744      1.333      1.042       5053        640: 100%|██████████| 3/3 [01:01<00:00, 20.65\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [01:03<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.693      0.382      0.451      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      8.94G      1.662      1.374      1.042       6531        640: 100%|██████████| 3/3 [00:50<00:00, 16.88\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.752      0.381      0.478      0.288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      8.12G      1.707      1.366      1.037       6211        640: 100%|██████████| 3/3 [00:45<00:00, 15.24\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:28<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.725      0.407      0.497        0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      5.75G      1.688      1.326      1.035       5192        640: 100%|██████████| 3/3 [00:50<00:00, 16.86\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.725      0.407      0.497        0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      7.46G      1.682      1.329      1.028       4095        640: 100%|██████████| 3/3 [00:36<00:00, 12.00\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:30<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.697      0.424      0.508      0.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      7.15G      1.634      1.304      1.032       5073        640: 100%|██████████| 3/3 [00:39<00:00, 13.21\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:30<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.687      0.443      0.525      0.314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      8.38G      1.702      1.308      1.027       4936        640: 100%|██████████| 3/3 [00:53<00:00, 17.80\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:21<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.684      0.457      0.537       0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50       5.6G      1.666      1.183      1.033       2860        640: 100%|██████████| 3/3 [00:21<00:00,  7.05\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.684      0.457      0.537       0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      3.69G       1.56       1.12      1.022       2831        640: 100%|██████████| 3/3 [00:00<00:00,  3.06\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.679      0.472      0.544      0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      5.61G      1.583      1.067      1.009       2597        640: 100%|██████████| 3/3 [00:16<00:00,  5.61\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:15<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.687      0.473       0.55      0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      4.09G      1.529      1.064       1.01       3568        640: 100%|██████████| 3/3 [00:07<00:00,  2.37\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.693      0.473       0.55      0.327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      4.81G      1.583      1.083      1.015       3105        640: 100%|██████████| 3/3 [00:19<00:00,  6.44\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.693      0.473       0.55      0.327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      5.96G      1.574      1.079      1.014       2845        640: 100%|██████████| 3/3 [00:19<00:00,  6.53\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.698      0.482      0.558      0.332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      5.93G      1.526      1.072      1.015       2646        640: 100%|██████████| 3/3 [00:21<00:00,  7.05\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.719       0.48      0.562       0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      5.04G      1.473      1.026     0.9981       3198        640: 100%|██████████| 3/3 [00:17<00:00,  5.77\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.736      0.481      0.568      0.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      5.67G      1.518      1.026      1.001       2936        640: 100%|██████████| 3/3 [00:18<00:00,  6.08\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.736      0.481      0.568      0.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      5.42G      1.445     0.9938      0.985       3121        640: 100%|██████████| 3/3 [00:14<00:00,  4.87\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:15<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.736      0.486      0.574       0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 0.911 hours.\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train2\\weights\\best.pt...\n",
      "Ultralytics 8.3.126  Python-3.9.18 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.735      0.486      0.574      0.349\n",
      "                 Price         40       1676      0.705      0.369      0.442      0.246\n",
      "               Product         44       9771      0.766      0.603      0.705      0.453\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Tạo file cấu hình YAML\n",
    "yaml_file = 'C:/Users/minhk/Downloads/IoT/model/dataset/data.yaml'\n",
    "\n",
    "# Khởi tạo mô hình (có thể chọn kích thước phù hợp: n, s, m, l, x)\n",
    "model = YOLO('yolov8n.pt')  # load pretrained model\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "results = model.train(\n",
    "    data=yaml_file,\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    patience=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cce61ff3-5295-48c2-95ac-ddd8d1b3d452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\001.jpg: 448x640 268 Products, 49.5ms\n",
      "Speed: 4.8ms preprocess, 49.5ms inference, 14.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\001.jpg: {'Product': 240}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\002.jpg: 448x640 300 Products, 47.4ms\n",
      "Speed: 4.9ms preprocess, 47.4ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\002.jpg: {'Product': 300}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\003.jpg: 448x640 18 Prices, 144 Products, 48.3ms\n",
      "Speed: 6.7ms preprocess, 48.3ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\003.jpg: {'Product': 83, 'Price': 3}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\004.jpg: 352x640 34 Prices, 245 Products, 35.8ms\n",
      "Speed: 5.6ms preprocess, 35.8ms inference, 4.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\004.jpg: {'Product': 158, 'Price': 8}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\005.jpg: 384x640 242 Products, 38.7ms\n",
      "Speed: 4.6ms preprocess, 38.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\005.jpg: {'Product': 144}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\006.jpg: 448x640 9 Prices, 58 Products, 49.1ms\n",
      "Speed: 5.2ms preprocess, 49.1ms inference, 3.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\006.jpg: {'Product': 52, 'Price': 3}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\007.jpg: 480x640 3 Prices, 289 Products, 50.4ms\n",
      "Speed: 5.7ms preprocess, 50.4ms inference, 9.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\007.jpg: {'Product': 195, 'Price': 1}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\008.jpg: 320x640 5 Prices, 216 Products, 32.8ms\n",
      "Speed: 5.7ms preprocess, 32.8ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\008.jpg: {'Product': 145, 'Price': 2}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\009.jpg: 448x640 46 Prices, 122 Products, 49.5ms\n",
      "Speed: 6.5ms preprocess, 49.5ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\009.jpg: {'Product': 79, 'Price': 15}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\010.jpg: 384x640 4 Prices, 59 Products, 38.1ms\n",
      "Speed: 4.4ms preprocess, 38.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\010.jpg: {'Product': 57}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\011.jpg: 640x544 26 Products, 56.6ms\n",
      "Speed: 7.1ms preprocess, 56.6ms inference, 9.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\011.jpg: {'Product': 21}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\012.jpg: 640x480 300 Products, 49.6ms\n",
      "Speed: 5.3ms preprocess, 49.6ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\012.jpg: {'Product': 289}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\013.jpg: 448x640 53 Prices, 174 Products, 48.9ms\n",
      "Speed: 6.9ms preprocess, 48.9ms inference, 2.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\013.jpg: {'Price': 29, 'Product': 90}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\014.jpg: 640x544 99 Products, 57.9ms\n",
      "Speed: 7.3ms preprocess, 57.9ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\014.jpg: {'Product': 66}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\015.jpg: 448x640 41 Prices, 165 Products, 49.9ms\n",
      "Speed: 8.3ms preprocess, 49.9ms inference, 6.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\015.jpg: {'Product': 132, 'Price': 20}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\016.jpg: 448x640 76 Prices, 224 Products, 47.6ms\n",
      "Speed: 5.7ms preprocess, 47.6ms inference, 3.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\016.jpg: {'Product': 224, 'Price': 76}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\017.jpg: 640x480 8 Prices, 54 Products, 51.2ms\n",
      "Speed: 5.8ms preprocess, 51.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\017.jpg: {'Product': 49, 'Price': 7}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\018.jpg: 640x640 53 Prices, 182 Products, 67.0ms\n",
      "Speed: 11.8ms preprocess, 67.0ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\018.jpg: {'Product': 95, 'Price': 39}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\019.jpg: 640x448 11 Prices, 125 Products, 45.9ms\n",
      "Speed: 4.8ms preprocess, 45.9ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\019.jpg: {'Product': 96, 'Price': 5}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\020.jpg: 640x512 1 Price, 137 Products, 54.9ms\n",
      "Speed: 10.0ms preprocess, 54.9ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\020.jpg: {'Product': 45}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\021.jpg: 480x640 5 Prices, 60 Products, 51.7ms\n",
      "Speed: 6.0ms preprocess, 51.7ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\021.jpg: {'Product': 45, 'Price': 1}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\022.jpg: 480x640 16 Prices, 104 Products, 49.0ms\n",
      "Speed: 5.3ms preprocess, 49.0ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\022.jpg: {'Product': 67, 'Price': 10}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\023.jpg: 480x640 300 Products, 48.8ms\n",
      "Speed: 5.3ms preprocess, 48.8ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\023.jpg: {'Product': 284}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\024.jpg: 480x640 7 Prices, 53 Products, 49.0ms\n",
      "Speed: 5.8ms preprocess, 49.0ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\024.jpg: {'Product': 46, 'Price': 6}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\025.jpg: 640x480 5 Prices, 181 Products, 50.3ms\n",
      "Speed: 7.0ms preprocess, 50.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\025.jpg: {'Product': 169, 'Price': 3}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\026.jpg: 640x480 9 Prices, 92 Products, 48.3ms\n",
      "Speed: 5.9ms preprocess, 48.3ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\026.jpg: {'Product': 92}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\027.jpg: 448x640 63 Products, 49.4ms\n",
      "Speed: 5.6ms preprocess, 49.4ms inference, 3.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\027.jpg: {'Product': 63}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\028.jpg: 640x512 191 Products, 55.3ms\n",
      "Speed: 11.2ms preprocess, 55.3ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\028.jpg: {'Product': 121}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\029.jpg: 480x640 11 Prices, 193 Products, 51.3ms\n",
      "Speed: 7.0ms preprocess, 51.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\029.jpg: {'Product': 119, 'Price': 8}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\030.jpg: 480x640 137 Products, 48.6ms\n",
      "Speed: 4.8ms preprocess, 48.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\030.jpg: {'Product': 48}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\031.jpg: 448x640 34 Prices, 203 Products, 48.6ms\n",
      "Speed: 4.6ms preprocess, 48.6ms inference, 3.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\031.jpg: {'Price': 27, 'Product': 140}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\032.jpg: 416x640 41 Prices, 150 Products, 47.1ms\n",
      "Speed: 4.7ms preprocess, 47.1ms inference, 3.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\032.jpg: {'Price': 28, 'Product': 130}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\033.jpg: 544x640 161 Products, 56.0ms\n",
      "Speed: 6.2ms preprocess, 56.0ms inference, 3.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\033.jpg: {'Product': 96}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\034.jpg: 480x640 17 Prices, 219 Products, 50.0ms\n",
      "Speed: 5.7ms preprocess, 50.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\034.jpg: {'Product': 115, 'Price': 14}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\035.jpg: 352x640 34 Prices, 245 Products, 35.1ms\n",
      "Speed: 4.9ms preprocess, 35.1ms inference, 2.8ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\035.jpg: {'Product': 158, 'Price': 8}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\036.jpg: 608x640 24 Prices, 150 Products, 62.7ms\n",
      "Speed: 6.4ms preprocess, 62.7ms inference, 3.6ms postprocess per image at shape (1, 3, 608, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\036.jpg: {'Price': 13, 'Product': 120}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\037.jpg: 640x480 1 Price, 142 Products, 50.6ms\n",
      "Speed: 5.0ms preprocess, 50.6ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\037.jpg: {'Product': 77}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\038.jpg: 640x480 267 Products, 47.8ms\n",
      "Speed: 4.9ms preprocess, 47.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\038.jpg: {'Product': 169}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\039.jpg: 448x640 65 Products, 49.3ms\n",
      "Speed: 4.7ms preprocess, 49.3ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\039.jpg: {'Product': 49}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\040.jpg: 640x448 14 Prices, 76 Products, 46.2ms\n",
      "Speed: 7.7ms preprocess, 46.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\040.jpg: {'Product': 56, 'Price': 9}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\041.jpg: 448x640 84 Prices, 156 Products, 49.6ms\n",
      "Speed: 4.8ms preprocess, 49.6ms inference, 3.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\041.jpg: {'Price': 51, 'Product': 72}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\042.jpg: 480x640 48 Products, 51.2ms\n",
      "Speed: 5.3ms preprocess, 51.2ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\042.jpg: {'Product': 32}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\043.jpg: 480x640 51 Prices, 97 Products, 49.0ms\n",
      "Speed: 4.8ms preprocess, 49.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\043.jpg: {'Product': 79, 'Price': 35}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\044.jpg: 448x640 1 Price, 179 Products, 49.4ms\n",
      "Speed: 4.6ms preprocess, 49.4ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\044.jpg: {'Product': 153}\n",
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\IoT\\dataset\\Supermarket_shelves\\images\\045.jpg: 640x448 67 Products, 45.5ms\n",
      "Speed: 6.1ms preprocess, 45.5ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processed C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\\045.jpg: {'Product': 59}\n",
      "\n",
      "Total objects detected in all images:\n",
      "Product: 5119\n",
      "Price: 421\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Đường dẫn tới model đã huấn luyện\n",
    "MODEL_PATH = 'C:/Users/minhk/Downloads/IoT/runs/detect/train2/weights/best.pt'  # Đổi thành đường dẫn của bạn\n",
    "OUTPUT_DIR = 'C:/Users/minhk/Downloads/IoT/output'\n",
    "\n",
    "# Tải model\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "def count_objects(image_path, conf_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Phát hiện và đếm đối tượng trên ảnh.\n",
    "    \"\"\"\n",
    "    results = model(image_path)\n",
    "    detections = results[0]\n",
    "    boxes = detections.boxes\n",
    "    class_counts = Counter()\n",
    "    for box in boxes:\n",
    "        class_id = int(box.cls[0])\n",
    "        class_name = model.names[class_id]\n",
    "        confidence = float(box.conf[0])\n",
    "        if confidence > conf_threshold:\n",
    "            class_counts[class_name] += 1\n",
    "    return class_counts, detections\n",
    "\n",
    "def visualize_detection(image_path, results, conf_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Vẽ bounding box và ghi nhãn lên ảnh.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        class_id = int(box.cls[0])\n",
    "        class_name = model.names[class_id]\n",
    "        confidence = float(box.conf[0])\n",
    "        if confidence > conf_threshold:\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            label = f\"{class_name}: {confidence:.2f}\"\n",
    "            cv2.putText(img, label, (x1, max(0, y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    return img\n",
    "\n",
    "def process_directory(input_dir, output_dir=OUTPUT_DIR, conf_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Xử lý toàn bộ ảnh trong thư mục, lưu ảnh kết quả ra output_dir.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    image_files = glob(os.path.join(input_dir, '*.jpg')) + \\\n",
    "                  glob(os.path.join(input_dir, '*.png'))\n",
    "    \n",
    "    total_counts = Counter()\n",
    "    for img_path in image_files:\n",
    "        counts, detections = count_objects(img_path, conf_threshold)\n",
    "        total_counts += counts\n",
    "        output_img = visualize_detection(img_path, detections, conf_threshold)\n",
    "        output_path = os.path.join(output_dir, os.path.basename(img_path))\n",
    "        cv2.imwrite(output_path, output_img)\n",
    "        print(f\"Processed {img_path}: {dict(counts)}\")\n",
    "    \n",
    "    print(\"\\nTotal objects detected in all images:\")\n",
    "    for class_name, count in total_counts.items():\n",
    "        print(f\"{class_name}: {count}\")\n",
    "\n",
    "    return total_counts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Đổi đường dẫn thành thư mục chứa ảnh cần nhận diện\n",
    "    input_directory = \"C:/Users/minhk/Downloads/IoT/dataset/Supermarket_shelves/images\"\n",
    "    process_directory(input_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89035206-858a-4639-9708-0e7decbd87fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.126  Python-3.9.18 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 1560.5772.1 MB/s, size: 3255.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\labels.cache... 45 images, 0 backgrounds, 1 corrupt: 100%|████\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\005.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\009.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.3022      1.3223      1.0841      1.0744      1.0623      1.0945      1.0893      1.1579      1.0835      1.2695      1.3175       1.113      1.3259       1.207       1.029      1.0884      1.3348      1.0344      1.3302      1.3182      1.3013        1.33      1.3374      1.0893      1.0893      1.0747\n",
      "      1.0867      1.2417      1.0791      1.3228      1.0311      1.3339      1.3348      1.1824      1.3214      1.3235      1.2944       1.205      1.1221      1.2463      1.1656      1.0813      1.3266      1.3296      1.0859        1.33      1.0919      1.1205      1.0911      1.0887      1.0792      1.3214\n",
      "      1.3395]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\018.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\022.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\031.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\IoT\\model\\dataset\\images\\041.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:17<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         44      11447      0.721      0.487      0.573       0.35\n",
      "                 Price         40       1676       0.69      0.364       0.44      0.247\n",
      "               Product         44       9771      0.751       0.61      0.705      0.452\n",
      "Speed: 4.2ms preprocess, 113.2ms inference, 0.0ms loss, 49.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n",
      "mAP@0.5: 0.5726136437958727\n",
      "mAP@0.5:0.95: 0.3495889517341878\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "validation_results = model.val()\n",
    "print(f\"mAP@0.5: {validation_results.box.map50}\")\n",
    "print(f\"mAP@0.5:0.95: {validation_results.box.map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0361d74d-f4fa-471f-9304-51a7673b78f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
